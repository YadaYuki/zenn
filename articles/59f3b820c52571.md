---
title: "PyTorch„ÅßËá™‰Ωú„Åó„Å¶ÁêÜËß£„Åô„ÇãTransformer"
emoji: "üôä"
type: "tech" # tech: ÊäÄË°ìË®ò‰∫ã / idea: „Ç¢„Ç§„Éá„Ç¢
topics: ["python","pytorch","Ê©üÊ¢∞Â≠¶Áøí","transformer"]
published: false
---



## 1. „ÅØ„Åò„ÇÅ„Å´

Transformer„ÅØ2017Âπ¥„Å´„ÄåAttention is all you need„Äç„Å®„ÅÑ„ÅÜË´ñÊñá„ÅßÁô∫Ë°®„Åï„Çå„ÄÅËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜÁïå„Å´„Éñ„É¨„Ç§„ÇØ„Çπ„É´„Éº„ÇíÂ∑ª„ÅçËµ∑„Åì„Åó„ÅüÊ∑±Â±§Â≠¶Áøí„É¢„Éá„É´„Åß„Åô„ÄÇË´ñÊñáÂÜÖ„Åß„ÅØ„ÄÅËã±Ë™û‚Üí„Éâ„Ç§„ÉÑË™ûÁøªË®≥„ÉªËã±Ë™û‚Üí„Éï„É©„É≥„ÇπË™ûÁøªË®≥„Å®„ÅÑ„ÅÜ‰∫å„Å§„ÅÆÊ©üÊ¢∞ÁøªË®≥„Çø„Çπ„ÇØ„Å´„Çà„ÇãÊÄßËÉΩË©ï‰æ°„ÅåË°å„Çè„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„Çå„Åæ„ÅßÊúÄ„ÇÇÈ´ò„ÅÑÁ≤æÂ∫¶„ÇíÂá∫„Åô„Å®„Åï„Çå„Å¶„ÅÑ„ÅüCNN,RNN(LSTM)„Éô„Éº„Çπ„ÅÆÊ©üÊ¢∞ÁøªË®≥„Å®ÊØîËºÉ„Åó„Å¶„ÄÅ

- Á≤æÂ∫¶(Bleu„Çπ„Ç≥„Ç¢)
- Ë®ìÁ∑¥„Å´„Åã„Åã„Çã„Ç≥„Çπ„Éà„ÅÆÂ∞ë„Å™„Åï

„Å®„ÅÑ„ÅÜ‰∏°Êñπ„ÅÆÈù¢„Åß„ÄÅTransformer„ÅØ„Åù„Çå„Çâ„ÅÆÊÄßËÉΩ„Çí‰∏äÂõû„Çä„Åæ„Åó„Åü„ÄÇ‰ª•Èôç„ÄÅTransformer„Çí„Éô„Éº„Çπ„Å®„Åó„ÅüÊßò„ÄÖ„Å™„É¢„Éá„É´„ÅåÊèêÊ°à„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„ÅÆ‰æã„Å®„Åó„Å¶„ÅØ„ÄÅBERT,XLNet,GPT-3„Å®„ÅÑ„Å£„ÅüËøëÂπ¥„ÅÆSoTA„Å®„Åï„Çå„Å¶„ÅÑ„Çã„É¢„Éá„É´„ÅåÊåô„Åí„Çâ„Çå„Åæ„Åô„ÄÇ

„Åì„Åì„Åß„ÄÅ„ÄåAttention is all you need„ÄçÂÜÖ„Å´Êé≤Ëºâ„Åï„Çå„Å¶„ÅÑ„ÇãTransformer„ÅÆÊßãÈÄ†„ÅÆÂõ≥„ÇíË¶ã„Å¶„Åø„Åæ„Åó„Çá„ÅÜ

![Transformer](https://user-images.githubusercontent.com/57289763/160270884-e1901241-a1e6-4890-a5e8-165e87f0c4da.png)

„Éã„É•„Éº„É©„É´Ê©üÊ¢∞ÁøªË®≥„Å´„Åä„Åë„ÇãTransformer„ÅØ**„ÅÇ„ÇãÊôÇÁ≥ªÂàó„Éá„Éº„Çø„ÇíÂà•„ÅÆÊôÇÁ≥ªÂàó„Éá„Éº„Çø„Å´Â§âÊèõ„Åô„Çã(Ex:Êó•Êú¨Ë™û„Å´„Çà„ÇãÊñáÁ´†„ÇíËã±Ë™û„Å´„Çà„ÇãÊñáÁ´†„Å´ÁøªË®≥„Åô„Çã)„Çà„ÅÜ„Å™„Çø„Çπ„ÇØ„Å´Áî®„ÅÑ„Çâ„Çå„ÇãEncoder-Decoder(seq2seq)„ÅÆÊßãÈÄ†„Çí„Åó„Å¶„ÅÑ„Çã**„Å®„ÅÑ„ÅÜÁÇπ„Åß„ÅØRNN/LSTM„Éô„Éº„Çπ„ÅÆ„É¢„Éá„É´„Å®Âêå„Åò„Åß„Åô„ÄÇ

„Åó„Åã„Åó„ÄÅTransformer„ÅÆ**ÊúÄÂ§ß„ÅÆÁâπÂæ¥„ÅØEncoder„ÉªDecoder„ÅÆ„ÅÑ„Åö„Çå„Å´„ÇÇRNN„ÇÑLSTM„ÅÆ„Çà„ÅÜ„Å™ÂÜçÂ∏∞Ë®àÁÆó„ÇíÂøÖË¶Å„Å®„Åô„ÇãÂ±§„ÅåÂ≠òÂú®„Åõ„Åö„ÄÅ„Åù„ÅÆ‰ª£„Çè„Çä„Å®„Åó„Å¶„Åì„ÅÆÂæåË™¨Êòé„Åô„ÇãAttention„ÅåÁî®„ÅÑ„Çâ„Çå„Å¶„ÅÑ„ÇãÁÇπ**„Åß„Åô„ÄÇ

Transformer„ÅØËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜ„ÅÆ„Åø„Å™„Çâ„Åö„ÄÅ‰ªñ„ÅÆÂàÜÈáé„Åß„ÇÇÁî®„ÅÑ„Çâ„Çå„ÇãÊ±éÁî®ÊÄß„ÅÆÈ´ò„ÅÑ„É¢„Éá„É´„Åß„Åô„ÄÇ„Åù„ÅÆ„Åü„ÇÅ„ÄÅ‰∏ªË¶Å„Å™„Éá„Ç£„Éº„Éó„É©„Éº„Éã„É≥„Ç∞„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„ÅÇ„Çã[Pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)„Éª[Tensorflow](https://tensorflow.github.io/tensor2tensor/#language-modeling)„ÅÆ„ÅÑ„Åö„Çå„Å´„ÇÇÊó¢„Å´ÂÖ¨ÂºèÂÆüË£Ö„ÅåÂ≠òÂú®„Åó„Å¶„Åä„Çä„ÄÅÁ†îÁ©∂Á≠â„ÇíÁõÆÁöÑ„Å´ÂÆüË£Ö„Åô„ÇãÈöõ„ÅØ„Åì„Çå„Çâ„ÇíÁî®„ÅÑ„Çã„ÅÆ„Åå‰∏ÄËà¨ÁöÑ„Åã„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ

„Åó„Åã„Åó„ÄÅ‰Ωú„Çã„Åì„Å®„ÅØÁêÜËß£„Åô„Çã„Åì„Å®„Å∏„ÅÆËøëÈÅì„ÄÇ„Å®„ÅÑ„ÅÜ„Åì„Å®„Åß„ÄÅ‰ªäÂõû„ÅØÂèñ„ÇäÁµÑ„Çì„Å†„ÅÆ„ÅØTransformer„Å®Transformer„ÇíÊßãÊàê„Åô„ÇãÂ±§„ÅÆ„Çπ„ÇØ„É©„ÉÉ„ÉÅÂÆüË£Ö„Åß„Åô„ÄÇÊú¨Ë®ò‰∫ã„Åß„ÅØ„ÄÅTransformer„É¢„Éá„É´„ÇíÊßãÊàê„Åô„ÇãÂêÑ„É¨„Ç§„É§„ÅÆÁêÜË´ñÁöÑËÉåÊôØ„Åä„Çà„Å≥Pytorch„Å´„Çà„ÇãÂÆüË£Ö„ÇíÁ¥π‰ªã„Åó„Å¶„ÅÑ„Åç„Åæ„Åô„ÄÇ‰ª•‰∏ã„ÅØÂÆüË£Ö„Åó„Åü„É™„Éù„Ç∏„Éà„É™„Å´„Å™„Çä„Åæ„Åô„ÄÇ

https://github.com/YadaYuki/en_ja_translator_pytorch
 


## 2. „Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÊàêÊ¶ÇË¶≥

„Åù„Çå„Åß„ÅØ„ÄÅÊó©ÈÄüÂÆüË£Ö„ÇíË¶ã„Å¶„ÅÑ„Åç„Åæ„Åó„Çá„ÅÜ„ÄÇÁ¥∞ÈÉ®„Å´Ê≥®ÁõÆ„Åô„ÇãÂâç„Å´„ÄÅ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅÆÂÖ®‰ΩìÂÉè„ÇíÊ¶ÇË¶≥„Åó„Åæ„Åô„ÄÇ„Å®„ÅÑ„ÅÜ„Åì„Å®„Åß„ÄÅ„Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÊàê„ÅØ‰ª•‰∏ã„ÅÆÈÄö„Çä„Å´„Å™„Çä„Åæ„Åô„ÄÇ

```
.
‚îú‚îÄ‚îÄ const // path„Å™„Å©„ÅÆÂÆöÊï∞ÂÄ§
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ path.py
‚îú‚îÄ‚îÄ corpus // Ë®ìÁ∑¥Áî®„ÅÆ„Éá„Éº„Çø„Éª„Ç≥„Éº„Éë„Çπ„ÅåÂÖ•„Çã
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ kftt-data-1.0
‚îú‚îÄ‚îÄ figure
‚îú‚îÄ‚îÄ layers // Ê∑±Â±§„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÇíÊßãÊàê„Åô„Çã„É¨„Ç§„É§„ÅÆÂÆüË£Ö
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ transformer
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ Embedding.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ FFN.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ MultiHeadAttention.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ PositionalEncoding.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ScaledDotProductAttention.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ TransformerDecoder.py
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ TransformerEncoder.py
‚îú‚îÄ‚îÄ models // Ê∑±Â±§„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„É¢„Éá„É´„ÅÆÂÆüË£Ö
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ Transformer.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ mypy.ini
‚îú‚îÄ‚îÄ pickles // „É¢„Éá„É´„ÇÑ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆpickle„Éï„Ç°„Ç§„É´„ÇíÊ†ºÁ¥ç
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ nn/
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ poetry.toml
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ tests // „ÉÜ„Çπ„Éà(pytest)
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ conftest.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ layers/
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models/
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ train.py // Ë®ìÁ∑¥Áî®„Ç≥„Éº„Éâ
‚îî‚îÄ‚îÄ utils // Dataset„ÇÑVocab„Å®„ÅÑ„Å£„Åü„ÇØ„É©„Çπ„ÅÆÂÆüË£Ö,ÂâçÂá¶ÁêÜ„Å´Áî®„ÅÑ„ÇãÈñ¢Êï∞„ÅÆÂÆüË£Ö
    ‚îú‚îÄ‚îÄ dataset/
    ‚îú‚îÄ‚îÄ download.py
    ‚îú‚îÄ‚îÄ evaluation/
    ‚îî‚îÄ‚îÄ text/
```

`poetry.*`„Å®„ÅÑ„ÅÜÂêçÂâç„ÅÆ„Éï„Ç°„Ç§„É´„ÅåÂ≠òÂú®„Åô„Çã„Åì„Å®„Åã„Çâ„Çè„Åã„ÇãÈÄö„Çä„ÄÅ„É©„Ç§„Éñ„É©„É™„ÅÆ„Éë„ÉÉ„Ç±„Éº„Ç∏ÁÆ°ÁêÜ„Å´„ÅØ[Poetry](https://python-poetry.org/)„ÇíÊé°Áî®„Åó„Åæ„Åó„Åü„ÄÇPoetry„Å´„ÅØ„ÄÅ

- `poetry install`„Ç≥„Éû„É≥„Éâ‰∏Ä„Å§„ÅßÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„ÇíÂÖ®„Å¶„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„ÄÅ‰ªÆÊÉ≥Áí∞Â¢É„Çí‰ΩúÊàê„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Çã.
- ÈñãÁô∫ÊôÇ„ÅÆ„ÅøÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Å®ÈñãÁô∫ÊôÇ„Å®Êú¨Áï™Áí∞Â¢É„ÅÆ‰∏°Êñπ„ÅßÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Çí‰∏Ä„Å§„ÅÆ„Éï„Ç°„Ç§„É´(pyproject.toml)„ÅßÂÆöÁæ©„Åß„Åç„Çã.

„Å™„Å©„ÅÆ„É°„É™„ÉÉ„Éà„Åå„ÅÇ„Çä„Åæ„Åô.

„Éï„Ç©„É´„ÉÄÊßãÊàê„Å®„Åó„Å¶„ÅØ„ÄÅ`models`‰ª•‰∏ã„Å´„ÄåTransformerÊú¨‰Ωì„Äç„ÄÅ`layers`‰ª•‰∏ã„Å´„ÄåTransformer„ÇíÊßãÊàê„Åô„Çã„É¨„Ç§„É§„Éº„Äç„Å®„ÅÑ„ÅÜÊ¨°Á´†„ÅßË™¨Êòé„Åô„ÇãÂÆüË£Ö„Å´Ë©≤ÂΩì„Åô„Çã„Éï„Ç°„Ç§„É´„ÅåÂ≠òÂú®„Åó„Åæ„Åô„ÄÇ

## 3. Transformer„ÇíÊßãÊàê„Åô„ÇãÂ±§

„Åù„Çå„Åß„ÅØ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅÆÂÖ®‰ΩìÂÉè„ÅåÊé¥„ÇÅ„Åü„Å®„Åì„Çç„Åß„ÄÅÂêÑÂ±§„ÅÆÂÆüË£Ö„ÇíË¶ã„Å¶„ÅÑ„Åç„Åæ„Åó„Çá„ÅÜ„ÄÇ
## 3.1 Attention

ÂÖà„Åª„Å©„ÇÇËø∞„Åπ„ÅüÈÄö„Çä„ÄÅTransformer„ÅÆÊúÄÂ§ß„ÅÆÁâπÂæ¥„ÅØ**RNN„ÅÆ„Çà„ÅÜ„Å´Ë®ìÁ∑¥ÊôÇ„ÅÆÂÜçÂ∏∞Ë®àÁÆó„ÇíË°å„Çè„Åö„Å´„ÄÅAttentionÂ±§„ÇíÁî®„ÅÑ„Å¶„ÅÑ„ÇãÁÇπ**„Åß„Åô„ÄÇ„ÄåAttention is all you need„Äç„Å®„ÅÑ„ÅÜË´ñÊñá„ÅÆ„Çø„Ç§„Éà„É´„ÅåÁâ©Ë™û„Å£„Å¶„ÅÑ„Çã„Çà„ÅÜ„Å´„ÄÅAttention„ÅØTransformer„ÅÆ‰∏≠„ÅßÊúÄ„ÇÇÈáçË¶Å„Å™Â±§„Åß„Åô„ÄÇ„Åì„Åì„Åß„ÅØ„ÄÅTransformer„ÅÆÊ†∏„Å®„Å™„ÇãÂ±§„Åß„ÅÇ„ÇãAttentionÂ±§„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô„ÄÇ

AttentionÂ±§„ÅÆÁõÆÁöÑ„ÅØ„ÄÅÂÖ•Âäõ„Éô„ÇØ„Éà„É´„ÅÆÂêÑË¶ÅÁ¥†„ÅÆÈáçË¶ÅÂ∫¶„ÇíÁÆóÂá∫„Åó„ÄÅ„Åù„Çå„Å´„Çà„Å£„Å¶ÂÖ•Âäõ„Éô„ÇØ„Éà„É´„ÇíÈáç„Åø‰ªò„Åë„Çã„Åì„Å®„ÄÇAttentionÂ±§„Åß„ÅØ„ÄÅ**ÁîªÂÉè„ÇÑ„ÉÜ„Ç≠„Çπ„Éà„Å®„ÅÑ„Å£„ÅüÂÖ•Âäõ„Éá„Éº„Çø„ÅÆ„Éô„ÇØ„Éà„É´„ÅÆ‰∏≠„Åß„ÄÅÊ≠£„Åó„ÅÑÂá∫Âäõ„ÇíÂæó„Çã„Åü„ÇÅ„Å´ÈáçË¶Å„Å™Ë¶ÅÁ¥†„ÅØ„Å©„Çå„Åß„ÅÇ„Çã„ÅãÔºü„Å®„ÅÑ„ÅÜÈáçË¶ÅÂ∫¶„ÅÆÂΩπÂâ≤„ÇíÊûú„Åü„ÅôAttention Weight„Å®„ÅÑ„ÅÜÂÄ§„ÇíÁÆóÂá∫„Åó„Åæ„Åô**„ÄÇ

„ÄåÂÖ•Âäõ„Éô„ÇØ„Éà„É´„Äç„Å®„ÄåÁÆóÂá∫„Åó„ÅüAttention Weight„Äç„ÅÆÁ©ç„ÇíË®àÁÆó„Åô„Çã„Åì„Å®„Å´„Çà„Çä„ÄÅ**ÂÖ•Âäõ„Éô„ÇØ„Éà„É´„ÅÆ‰∏≠„ÅßÊ≠£Ëß£„É©„Éô„É´„ÇíÂæó„Çã‰∏ä„ÅßÁâπ„Å´ÈáçË¶Å„Å™Ë¶ÅÁ¥†„ÇíÈáç„Åø‰ªò„Åë**„Çã„Åì„Å®„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ

Attention„ÇíÂÆöÂºèÂåñ„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ„Åæ„Åö„ÅØ„ÄÅÈáçË¶ÅÂ∫¶„ÇíË°®„ÅôAttention Weight„ÅÆË®àÁÆó„Åß„Åô„ÄÇAttention Weight„ÇíÊ±Ç„ÇÅ„ÇãÈñ¢Êï∞$\alpha$„ÇíÁî®„ÅÑ„Å¶ÂÖ•ÂäõX„Å®Q(„ÇØ„Ç®„É™)„Åã„Çâ„ÄÅ X„ÅÆÈáçË¶ÅÂ∫¶„ÇíÊ±Ç„ÇÅ„Åæ„Åô„ÄÇ

$$ Attention Weight = \alpha(Q,X) $$

‰∏ä„ÅÆÂºè„ÅßÊ±Ç„ÇÅ„ÅüAttention Weight(X„ÅÆÈáçË¶ÅÂ∫¶)„ÅßÂÖ•ÂäõX„ÇíÈáç„Åø‰ªò„Åë„Åü„ÇÇ„ÅÆ„ÅåAttention„ÅÆÂá∫Âäõ„Å´„Å™„Çä„Åæ„Åô„ÄÇ

$$Output = (Attention Weight)X =\alpha(Q,X)X $$

„Åì„Åì„Åß„ÅØ„ÄÅ„ÄåAttention Weight„ÇíÁÆóÂá∫„Åó„ÄÅ„Åù„Çå„Å´„Çà„ÇäÂÖ•Âäõ„Éá„Éº„Çø„ÅåÈáç„Åø‰ªò„Åë„Çâ„Çå„Çã„Äç„Å®„ÅÑ„ÅÜÊºîÁÆó„ÅÆÊµÅ„Çå„Åå„Çè„Åã„Çã„Çà„ÅÜ„Å´„ÄÅ‰∏ä„ÅÆ„Çà„ÅÜ„Å™Âºè„ÅßAttentionÂ±§„Åß„ÅÆÊºîÁÆó„ÇíË°®„Åó„Åæ„Åó„Åü„ÄÇ„Åó„Åã„Åó„ÄÅÊú¨ÂÆ∂„ÅÆË´ñÊñáÂÜÖ„Åß„ÅØAttention„ÅÆÊºîÁÆó„Çí„ÄÅQ(„ÇØ„Ç®„É™),K(„Ç≠„Éº),V(„Éê„É™„É•„Éº)„Å®„ÅÑ„ÅÜ3„Å§„ÅÆË®òÂè∑„ÇíÁî®„ÅÑ„Å¶„ÄÅ

$$ Attention(Q,K,V) $$

„ÅÆ„Çà„ÅÜ„Å´Ë°®„Åó„Å¶„ÅÑ„Åæ„Åô.ÂÖàÁ®ã„ÅÆ$\alpha(Q,X)X$„Å®$Attention(Q,K,V)$„ÅØ„ÅÑ„Åö„Çå„ÇÇAttention„ÅÆÊºîÁÆó„Åß„ÅÇ„Çã„Åü„ÇÅ„ÄÅÊõ∏„ÅçÊñπ„ÅåÁï∞„Å™„Çã„Å†„Åë„Åß„ÄÅ„ÇÑ„Å£„Å¶„ÅÑ„Çã„Åì„Å®„ÅØÂÖ®„ÅèÂêå„Åò„Åß„Åô„ÄÇ

$\alpha(Q,X)X$„Çí$Attention(Q,K,V)$„Å´„Çà„Å£„Å¶Ë°®„Åô„Å®‰ª•‰∏ã„ÅÆÈÄö„Çä„Å´„Å™„Çä„Åæ„Åô.

$$Attention(Q,K,V) = Attention(Q,X,X) = \alpha(Q,X)X$$

‰ª•‰∏ä„ÅåAttentionÂ±§„ÅÆÊ¶ÇË¶Å„Å´Èñ¢„Åô„ÇãË™¨Êòé„Åß„Åô„ÄÇ

„Åï„Å¶„ÄÅÊú¨ÁØÄ„Åß„ÅØ„ÄÅAttentionÂ±§„ÅåË°å„ÅÜÊºîÁÆó„ÅÆÊ¶ÇË¶Å„Å®„Åù„ÅÆÁõÆÁöÑ„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åó„Åü„ÄÇ„Åó„Åã„ÅóËÇùÂøÉ„Å™„ÅÆ„ÅØ„ÄÅ**ÂÖ•Âäõ„ÅÆÈáçË¶ÅÂ∫¶„ÇíË°®„ÅôAttention Weight„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´ÁÆóÂá∫„Åô„Åπ„Åç„Åß„ÅÇ„Çã„ÅãÔºü„Å®„ÅÑ„ÅÜÁÇπ„Åß„Åô(Èñ¢Êï∞$\alpha$„Åå‰Ωï„Åß„ÅÇ„Çã„ÅãÔºü)**„ÄÇ

Transformer„Åß„ÅØ**„ÇØ„Ç®„É™Q,ÂÖ•Âäõ„Éá„Éº„ÇøX„ÅÆÂÜÖÁ©ç„ÇíË®àÁÆó„Åô„Çã„Åì„Å®„Å´„Çà„Å£„Å¶„ÄÅAttention Weight**„ÇíÁÆóÂá∫„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„ÅÆ„Çà„ÅÜ„Å™AttentionÂ±§„Çí**ScaledDotProductAttention**„Å®Âëº„Å≥„Åæ„Åô„ÄÇ

## 3.2 ScaledDotProductAttention

Transformer„ÅßÁî®„ÅÑ„Çâ„Çå„ÇãAttention„Åß„ÅÇ„ÇãScaledDotProductAttention„ÅÆAttention WeightË®àÁÆó„ÅØ„ÄÅ„ÇØ„Ç®„É™Q($N{\times}D$)„Å®ÂÖ•ÂäõX($N{\times}D$)„ÇíÁî®„ÅÑ„Å¶„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Âºè„ÅßË°®„Åô„Åì„Å®„Åå„Åß„Åç„Åæ„Åô.

$$\alpha(Q,X) = softmax(\frac{QX^T}{\sqrt{D}})$$

Ë≥™ÂïèÂøúÁ≠î„ÇÑÊ©üÊ¢∞ÁøªË®≥„Å®„ÅÑ„Å£„Åü„Çø„Çπ„ÇØ„Å´Transformer„É¢„Éá„É´„ÅßÂèñ„ÇäÁµÑ„Çì„Åß„ÅÑ„ÇãÂ†¥Âêà„ÄÅ‰∏ä„ÅÆÂºè„Å´„Åä„Åë„ÇãQ,X„ÅØ„Åù„Çå„Åû„ÇåÊñáÁ´†„Éá„Éº„Çø„ÇíË°åÂàó„ÅßË°®Áèæ„Åó„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇÊâ±„ÅÜ„Éá„Éº„Çø„ÅåNÂÄã„ÅÆÂçòË™û„ÇíÊåÅ„Å§ÊñáÁ´†„Çí„ÄÅDÊ¨°ÂÖÉ„ÅÆÂçòË™ûÂàÜÊï£Ë°®Áèæ„ÅßË°®Áèæ„Åó„Åü„Éá„Éº„Çø„Åß„ÅÇ„Å£„ÅüÂ†¥Âêà„ÄÅ$N{\times}D$„Å®„ÅÑ„ÅÜ„Çµ„Ç§„Ç∫„ÇíÊåÅ„Å§Ë°åÂàó„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô. 

„Åù„ÅÆ„Åü„ÇÅ„ÄÅ„Åì„ÅÆÊºîÁÆó„Åß„ÅØ„ÄÅ„ÇØ„Ç®„É™QÂÜÖ„ÅÆÂêÑÂçòË™û„ÅÆÂàÜÊï£Ë°®Áèæ„Å®ÂÖ•Âäõ„Éá„Éº„ÇøXÂÜÖ„ÅÆÂêÑÂçòË™û„ÅÆÂàÜÊï£Ë°®Áèæ„ÅÆÂÜÖÁ©ç„ÇíÁÆóÂá∫„Åó„Å¶„ÅÑ„Çã„ÄÅ„Å®„ÅÑ„ÅÜ„Åì„Å®„Åß„Åô„ÄÇ„Éô„ÇØ„Éà„É´ÂêåÂ£´„ÅÆÂÜÖÁ©ç„ÅåÂ§ß„Åç„ÅÑ„Å®„ÅÑ„ÅÜ„Åì„Å®„ÅØ„ÄÅÂêë„ÅÑ„Å¶„ÅÑ„ÇãÊñπÂêë„ÅåËøë„ÅÑ„ÄÅ„Åô„Å™„Çè„Å°„ÄÅ„Éô„ÇØ„Éà„É´ÂêåÂ£´„ÅÆÈ°û‰ººÂ∫¶„ÅåÈ´ò„ÅÑ„Å®„ÅÑ„ÅÜ„Åì„Å®„Åß„Åô(ÂçòË™ûÂêåÂ£´„ÅÆÈ°û‰ººÂ∫¶„ÅåÈ´ò„ÅÑ)„ÄÇ„Å§„Åæ„Çä„ÄÅScaledDotProductAttention„Å´ÊñáÁ´†„Éá„Éº„Çø„ÇíÂÖ•Âäõ„Åó„ÅüÂ†¥Âêà„ÄÅQ,XÂÜÖ„ÅÆÂçòË™ûÂêåÂ£´„ÅÆÈ°û‰ººÂ∫¶„Çí„ÄÅÂÖ•Âäõ„Å´ÂØæ„Åô„ÇãÈáçË¶ÅÊÄß„Å®„Åó„Å¶Èáç„Åø‰ªò„Åë„Å¶„ÅÑ„Çã„Å®Ëß£Èáà„Åô„Çã„Åì„Å®„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ

‰∏ä„ÅßÊ±Ç„ÇÅ„ÅüAttention Weight„Å®ÂÖ•ÂäõX„ÅÆÁ©ç„ÇíÊ±Ç„ÇÅ„Çã„Åì„Å®„ÅßÊúÄÁµÇÁöÑ„Å™Âá∫Âäõ„ÅåÂæó„Çâ„Çå„Åæ„Åô„ÄÇÂæì„Å£„Å¶„ÄÅÂÖ•ÂäõX,„ÇØ„Ç®„É™Q„Å´ÂØæ„Åô„ÇãScaledDotProductAttention„ÅÆÂá∫Âäõ„ÅØ‰ª•‰∏ã„ÅÆÂºè„ÅßË°®„Åô„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ

$$Attention(Q,K,V) = Attention(Q,X,X) = \alpha(Q,X)X = softmax(\frac{QX^T}{\sqrt{D}})X$$

„Åù„Çå„Åß„ÅØ„ÄÅ ScaledDotProductAttention„ÅÆPytorch„Å´„Çà„ÇãÂÆüË£Ö„ÇíË¶ã„Å¶„Åø„Åæ„Åó„Çá„ÅÜ.

```python
import numpy as np
import torch
from torch import nn


class ScaledDotProductAttention(nn.Module):
    def __init__(self, d_k: int) -> None:
        super().__init__()
        self.d_k = d_k

    def forward(
        self,
        q: torch.Tensor,  # =Q
        k: torch.Tensor,  # =X
        v: torch.Tensor,  # =X
        mask: torch.Tensor = None,
    ) -> torch.Tensor:
        scalar = np.sqrt(self.d_k)
        attention_weight = torch.matmul(q, torch.transpose(k, 1, 2)) / scalar # „ÄåQ * X^T / (D^0.5)„Äç" „ÇíË®àÁÆó

        if mask is not None: # mask„Å´ÂØæ„Åô„ÇãÂá¶ÁêÜ
            if mask.dim() != attention_weight.dim():
                raise ValueError(
                    "mask.dim != attention_weight.dim, mask.dim={}, attention_weight.dim={}".format(
                        mask.dim(), attention_weight.dim()
                    )
                )
            attention_weight = attention_weight.data.masked_fill_(
                mask, -torch.finfo(torch.float).max
            ) 

        attention_weight = nn.functional.softmax(attention_weight, dim=2) # Attention Weight„ÇíË®àÁÆó
        return torch.matmul(attention_weight, v) # (Attention Weight) * X „Å´„Çà„ÇäÈáç„Åø‰ªò„Åë.
```


## 3.3 Multihead Attention

4.2ÁØÄ„Åß„ÄÅTransformer„É¢„Éá„É´„ÅØAttention„ÅÆË®àÁÆóÊñπÊ≥ï„Å®„Åó„Å¶ScaledDotProductAttention„ÇíÊé°Áî®„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÇíË™¨Êòé„Åó„Åæ„Åó„Åü„ÄÇ

„Åó„Åã„Åó„ÄÅTransformer„ÅßÊé°Áî®„Åï„Çå„Å¶„ÅÑ„ÇãAttention„ÅØÂçò„Å™„ÇãScaledDotProductAttention„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇÂÆüÈöõ„ÅÆTransformer„Åß„ÅØÂçò‰∏Ä„ÅÆÂÖ•Âäõ„Å´ÂØæ„Åó„Å¶„ÄÅ**Ë§áÊï∞„ÅÆScaledDotProductAttention„Çí‰∏¶Âàó„ÅßÂÆüË°å„Åô„ÇãMultihead Attention**„Å®„ÅÑ„ÅÜ‰ªïÁµÑ„Åø„ÅåÊé°Áî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

„Åì„Åì„Åß„ÄÅÊú¨ÂÆ∂„ÅÆË´ñÊñá„Å´Êé≤Ëºâ„Åï„Çå„Å¶„ÅÑ„ÇãMultihead Attention„ÅÆÊ¶ÇË¶ÅÂõ≥„ÇíË¶ã„Å¶„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ

![Multihead Attention](https://user-images.githubusercontent.com/57289763/160265954-9451fb41-3906-4f29-8e74-d4255925141c.png)

Âõ≥‰∏≠„ÅÆh(„Éò„ÉÉ„ÉâÊï∞)„ÅØ‰∏¶ÂàóÂÆüË°å„Åô„ÇãScaledDotProductAttention„ÅÆÊï∞„ÇíË°®„Åó„Åæ„Åô.

Multihead Attention„Åß„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Âá¶ÁêÜ„ÅåË°å„Çè„Çå„Åæ„Åô„ÄÇ
1. AttentionÂ±§„Å´ÂØæ„Åô„ÇãÂÖ•Âäõ$Q$($N_{Q}$$\times$$d_{model}$),$K$($N$$\times$$d_{model}$),$V$($N$$\times$$d_{model}$)„Çí$h$(„Éò„ÉÉ„ÉâÊï∞)„ÅÆÊï∞„Å†„ÅëË§áË£Ω„Åô„Çã
2. Ë§áË£Ω„Åó„ÅüÂÖ•Âäõ$Q_i$,$K_i$,$V_i$(i=1~h)„ÇíË°åÂàó$W_i^q$($d_{model}$$\times$$d_k$),$W_i^k$($d_{model}$$\times$$d_k$),$W_i^v$($d_{model}$$\times$$d_v$)„Å´„Çà„Çä„ÄÅ$d_{model}$‚Üí$d_v$,$d_k$„Å∏„Å®Á∑öÂΩ¢Â§âÊèõ„Åô„Çã„ÄÇ
3. „Åù„ÅÜ„Åó„Å¶Âæó„Çâ„Çå„Åü$Q_i$$W_i^q$($N_Q$$\times$$d_k$),$K_i$$W^k_i$($N$$\times$$d_k$),$V_i$$W^v_i$($N$$\times$$d_v$)„ÇíhÂÄãÂ≠òÂú®„Åô„ÇãScaledDotProductAttention„Å∏ÂÖ•Âäõ„Åô„Çã
4. ‰∏¶ÂàóÂÆüË°å„Åï„Çå„ÅüScaledDotProductAttention„Åã„ÇâÂæó„Çâ„Çå„ÇãhÂÄã„ÅÆÂá∫Âäõhead(i=1~h,$N$$\times$$d_v$)„ÇíÁµêÂêà(concat)„Åó„ÄÅË°åÂàó$O$($N$$\times$$hd_v$)„ÇíÂæó„Çã„ÄÇ
5. $O$$W^O$„Å´„Çà„Çä$O$„Çí$hd_v$‚Üí$d_{model}$„Å´Á∑öÂΩ¢Â§âÊèõ„Åó„ÄÅÂæó„Çâ„Çå„ÅüÂÄ§„ÅåÊúÄÁµÇÁöÑ„Å™Âá∫Âäõ„Å®„Å™„Çã„ÄÇ

ÂÆöÂºèÂåñ„Åô„Çã„Å®‰ª•‰∏ã„ÅÆÈÄö„Çä„Å´„Å™„Çä„Åæ„Åô„ÄÇ


$$ head_i = ScaledDotProductAttention(Q_iW^q_i,K_iW^k_i,V_iW^v_i) (i = 1 \sim h)$$
$$ O = Concat(head_1, ..., head_h) $$
$$ MultiHead(Q,K,V) = OW^O $$


„Åù„Çå„Åß„ÅØ„ÄÅ‰ª•‰∏ä„ÇíË∏è„Åæ„Åà„Å¶„ÄÅÂÆüË£Ö„ÇíË¶ã„Å¶„ÅÑ„Åç„Åæ„Åó„Çá„ÅÜ.
```python
import torch
from layers.transformer.ScaledDotProductAttention import ScaledDotProductAttention
from torch import nn


class MultiHeadAttention(nn.Module):
    def __init__(self, d_model: int, h: int) -> None:
        super().__init__()
        self.d_model = d_model
        self.h = h
        self.d_k = d_model // h
        self.d_v = d_model // h

        #
        self.W_k = nn.Parameter(
            torch.Tensor(h, d_model, self.d_k)  # „Éò„ÉÉ„ÉâÊï∞, ÂÖ•ÂäõÊ¨°ÂÖÉ, Âá∫ÂäõÊ¨°ÂÖÉ(=ÂÖ•ÂäõÊ¨°ÂÖÉ/„Éò„ÉÉ„ÉâÊï∞)
        )

        self.W_q = nn.Parameter(
            torch.Tensor(h, d_model, self.d_k)  # „Éò„ÉÉ„ÉâÊï∞, ÂÖ•ÂäõÊ¨°ÂÖÉ, Âá∫ÂäõÊ¨°ÂÖÉ(=ÂÖ•ÂäõÊ¨°ÂÖÉ/„Éò„ÉÉ„ÉâÊï∞)
        )

        self.W_v = nn.Parameter(
            torch.Tensor(h, d_model, self.d_v)  # „Éò„ÉÉ„ÉâÊï∞, ÂÖ•ÂäõÊ¨°ÂÖÉ, Âá∫ÂäõÊ¨°ÂÖÉ(=ÂÖ•ÂäõÊ¨°ÂÖÉ/„Éò„ÉÉ„ÉâÊï∞)
        )

        self.scaled_dot_product_attention = ScaledDotProductAttention(self.d_k)

        self.linear = nn.Linear(h * self.d_v, d_model)

    def forward(
        self,
        q: torch.Tensor,
        k: torch.Tensor,
        v: torch.Tensor,
        mask_3d: torch.Tensor = None,
    ) -> torch.Tensor:

        batch_size, seq_len = q.size(0), q.size(1)

        """repeat Query,Key,Value by num of heads"""
        q = q.repeat(self.h, 1, 1, 1)  # head, batch_size, seq_len, d_model
        k = k.repeat(self.h, 1, 1, 1)  # head, batch_size, seq_len, d_model
        v = v.repeat(self.h, 1, 1, 1)  # head, batch_size, seq_len, d_model

        """Linear before scaled dot product attention"""
        q = torch.einsum(
            "hijk,hkl->hijl", (q, self.W_q)
        )  # head, batch_size, d_k, seq_len
        k = torch.einsum(
            "hijk,hkl->hijl", (k, self.W_k)
        )  # head, batch_size, d_k, seq_len
        v = torch.einsum(
            "hijk,hkl->hijl", (v, self.W_v)
        )  # head, batch_size, d_k, seq_len

        """Split heads"""
        q = q.view(self.h * batch_size, seq_len, self.d_k)
        k = k.view(self.h * batch_size, seq_len, self.d_k)
        v = v.view(self.h * batch_size, seq_len, self.d_v)

        if mask_3d is not None:
            mask_3d = mask_3d.repeat(self.h, 1, 1)

        """Scaled dot product attention"""
        attention_output = self.scaled_dot_product_attention(
            q, k, v, mask_3d
        )  # (head*batch_size, seq_len, d_model)

        attention_output = torch.chunk(attention_output, self.h, dim=0)
        attention_output = torch.cat(attention_output, dim=2)

        """Linear after scaled dot product attention"""
        output = self.linear(attention_output)
        return output
```


## 3.4 PositionalEncoding

## 3.5 Position-wise Feed-Forward Networks

## 3.6 Encoder
## 3.7 Decoder
## 3.8 Transformer(ÂÆåÊàêÁâà)
## .Ëã±Ë™û ‚Üí Êó•Êú¨Ë™ûÁøªË®≥Ê©ü„ÅÆÂ≠¶Áøí


:::details Trainer„ÇØ„É©„Çπ
```python
from os.path import join
from typing import List, Tuple

import torch
from matplotlib import pyplot as plt
from torch import nn, optim
from torch.utils.data import DataLoader

from const.path import (
    FIGURE_PATH,
    KFTT_TOK_CORPUS_PATH,
    NN_MODEL_PICKLES_PATH,
    TANAKA_CORPUS_PATH,
)
from models import Transformer
from utils.dataset.Dataset import KfttDataset
from utils.evaluation.bleu import BleuScore
from utils.text.text import tensor_to_text, text_to_tensor
from utils.text.vocab import get_vocab


class Trainer:
    def __init__(
        self,
        net: nn.Module,
        optimizer: optim.Optimizer,
        critetion: nn.Module,
        bleu_score: BleuScore,
        device: torch.device,
    ) -> None:
        self.net = net
        self.optimizer = optimizer
        self.critetion = critetion
        self.device = device
        self.bleu_score = bleu_score
        self.net = self.net.to(self.device)

    def loss_fn(self, preds: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:
        return self.critetion(preds, labels)

    def train_step(
        self, src: torch.Tensor, tgt: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor, float]:
        self.net.train()
        output = self.net(src, tgt)

        tgt = tgt[:, 1:]  # decoder„Åã„Çâ„ÅÆÂá∫Âäõ„ÅØ1 ~ max_len„Åæ„Åß„Å™„ÅÆ„Åß„ÄÅ0‰ª•Èôç„ÅÆ„Éá„Éº„Çø„ÅßË™§Â∑ÆÈñ¢Êï∞„ÇíË®àÁÆó„Åô„Çã
        output = output[:, :-1, :]  #

        # calculate loss
        loss = self.loss_fn(
            output.contiguous().view(
                -1,
                output.size(-1),
            ),
            tgt.contiguous().view(-1),
        )

        # calculate bleu score
        _, output_ids = torch.max(output, dim=-1)
        bleu_score = self.bleu_score(tgt, output_ids)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return loss, output, bleu_score

    def val_step(
        self, src: torch.Tensor, tgt: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor, float]:
        self.net.eval()
        output = self.net(src, tgt)

        tgt = tgt[:, 1:]
        output = output[:, :-1, :]  #

        loss = self.loss_fn(
            output.contiguous().view(
                -1,
                output.size(-1),
            ),
            tgt.contiguous().view(-1),
        )
        _, output_ids = torch.max(output, dim=-1)
        bleu_score = self.bleu_score(tgt, output_ids)

        return loss, output, bleu_score

    def fit(
        self, train_loader: DataLoader, val_loader: DataLoader, print_log: bool = True
    ) -> Tuple[List[float], List[float], List[float], List[float]]:
        # train
        train_losses: List[float] = []
        train_bleu_scores: List[float] = []
        if print_log:
            print(f"{'-'*20 + 'Train' + '-'*20} \n")
        for i, (src, tgt) in enumerate(train_loader):
            src = src.to(self.device)
            tgt = tgt.to(self.device)
            loss, _, bleu_score = self.train_step(src, tgt)
            src = src.to("cpu")
            tgt = tgt.to("cpu")

            if print_log:
                print(
                    f"train loss: {loss.item()}, bleu score: {bleu_score},"
                    + f"iter: {i+1}/{len(train_loader)} \n"
                )

            train_losses.append(loss.item())
            train_bleu_scores.append(bleu_score)

        # validation
        val_losses: List[float] = []
        val_bleu_scores: List[float] = []
        if print_log:
            print(f"{'-'*20 + 'Validation' + '-'*20} \n")
        for i, (src, tgt) in enumerate(val_loader):
            src = src.to(self.device)
            tgt = tgt.to(self.device)
            loss, _, bleu_score = self.val_step(src, tgt)
            src = src.to("cpu")
            tgt = tgt.to("cpu")

            if print_log:
                print(f"train loss: {loss.item()}, iter: {i+1}/{len(val_loader)} \n")

            val_losses.append(loss.item())
            val_bleu_scores.append(bleu_score)

        return train_losses, train_bleu_scores, val_losses, val_bleu_scores

    def test(self, test_data_loader: DataLoader) -> Tuple[List[float], List[float]]:
        test_losses: List[float] = []
        test_bleu_scores: List[float] = []
        for i, (src, tgt) in enumerate(test_data_loader):
            src = src.to(self.device)
            tgt = tgt.to(self.device)
            loss, _, bleu_score = trainer.val_step(src, tgt)
            src = src.to("cpu")
            tgt = tgt.to("cpu")

            test_losses.append(loss.item())
            test_bleu_scores.append(bleu_score)

        return test_losses, test_bleu_scores
```
:::

![image](https://user-images.githubusercontent.com/57289763/160236001-929f9221-12bd-464e-9c0e-29222228cd89.png)

Loss„ÅåÈ†ÜË™ø„Å´Ê∏õ„Å£„Å¶„ÅÑ„Çã„Åì„Å®„Åã„Çâ„ÄÅÊ≠£„Åó„ÅèÂ≠¶Áøí„Åß„Åç„Å¶„ÅÑ„Çã„Å®ËÄÉ„Åà„Çâ„Çå„Åæ„Åô.

## .„Åæ„Å®„ÇÅ
## .ÂèÇËÄÉÊñáÁåÆ

https://arxiv.org/abs/1706.03762

https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0-TensorFlow-Keras%E3%83%BBPyTorch%E3%81%AB%E3%82%88%E3%82%8B%E6%99%82%E7%B3%BB%E5%88%97%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-Compass-Books%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA/dp/4839969515

https://www.amazon.co.jp/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92-%E6%94%B9%E8%A8%82%E7%AC%AC2%E7%89%88-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%83%95%E3%82%A7%E3%83%83%E3%82%B7%E3%83%A7%E3%83%8A%E3%83%AB%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA-%E5%B2%A1%E8%B0%B7-%E8%B2%B4%E4%B9%8B/dp/4065133327

https://www.amazon.co.jp/PyTorch%E5%AE%9F%E8%B7%B5%E5%85%A5%E9%96%80-Eli-Stevens/dp/4839974691

https://www.amazon.co.jp/%E3%82%BC%E3%83%AD%E3%81%8B%E3%82%89%E4%BD%9C%E3%82%8BDeep-Learning-%E2%80%95%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E7%B7%A8-%E6%96%8E%E8%97%A4-%E5%BA%B7%E6%AF%85/dp/4873118360/ref=pd_bxgy_img_1/358-0651022-5160614?pd_rd_w=JO4Kw&pf_rd_p=020fee25-8ced-4191-bce3-27e7ce0c0e3b&pf_rd_r=WM1R7J4578P1B0MCNSJE&pd_rd_r=2b8a68ac-2514-4675-9132-acafd1cf2853&pd_rd_wg=kDhDj&pd_rd_i=4873118360&psc=1

https://qiita.com/halhorn/items/c91497522be27bde17ce

https://deeplearning.hatenablog.com/entry/transformer

