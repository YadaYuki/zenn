---
title: "Go製の全文検索エンジンOmochiを作った."
emoji: "😊"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Go","個人開発","情報検索"]
published: false
---

# 1.はじめに

膨大な量の電子データから目的となるデータを取得・抽出する情報検索。その技術は広く普及し、多くの人々が、様々な場面でその恩恵を受けています。[Google](https://google.com/)や[Bing](https://www.bing.com/)をはじめとした、世の中に大きなインパクトを与えるWeb検索がその代表例ですが、物件検索や論文検索、メール検索などその応用は様々です。

さて、今回取り組んだのは、Goによる転置インデックスを用いた全文検索エンジンのスクラッチ実装です。研究で自然言語処理を学んだことをきっかけに、情報検索や転置インデックスといったトピックに強い興味が湧いたので、Elasticsearch等には頼らず、ゼロから実装を行いました。以下、リポジトリになります。

https://github.com/YadaYuki/omochi/

本記事では、Omochiと多くの検索エンジンを支える転置インデックスというデータ構造およびOmochiの実装に関する説明を行なっていきます。

# 2.全文検索を支える転置インデックス

## 2.1 ニ種類の全文検索

検索エンジンは膨大な量の画像や文書といった電子データの中から、ユーザの情報要求に適合したアイテム群を抽出するソフトウェア・システムの総称です。その中でも文書群を対象に、**ユーザが要求する特定の文字列が含まれる文書を抽出する検索エンジンを全文検索エンジン(full-text search engine)と呼びます。**

そして、全文検索エンジンには大きく分けて

- **逐次検索(grep型)**
- **索引検索(インデックス型)**

というニ種類が存在します。

**逐次検索(grep型)** は、ユーザからの情報要求すなわち検索キーワードがsであった場合、検索対象となる文書のテキストを1文字ずつ走査し、文字列sが含まれるかを各文書に対して、チェックしていきます。

逐次検索は最もシンプルな手法であり、事前の前処理が不要であるというメリットがあります。しかし一方で、情報要求の都度、検索対象となる全ての文書を走査していく必要があります。従って、文書量と比例して、検索にかかる時間が増大していきます。そのため、大規模な文書に対する検索には効率が悪く、小規模な文書や一時的なテキストに対する検索に向いていると言えるでしょう。

大規模な文書群に対する全文検索では、 **索引検索(インデックス型)** を用いることが一般的です。索引検索では、検索対象となる文書から「インデックス(索引)」を事前に作成します。**インデックスは、特定の単語が、どの文書のどの位置に現れたのか？という情報が高速に取得しやすいようなデータ構造**が採用されています。

シグネチャファイルやsuffix treeなど文書からインデックスを作成する手法には、様々な手法が提案されています。その中でも、**長年に渡り多くの検索エンジンで用いられるのが転置インデックスと呼ばれるデータ構造です**。そして、今回作成した検索エンジンOmochiも、インデックスの作成手法として、転置インデックスを採用しています。

## 2.2 転置インデックス

転置インデックスは、文書郡内に登場する「単語$w$」と「単語wが登場する文書iに関する情報$D_i$(文書id、文書内で$w$が登場する位置や回数..etc)」を紐付けた以下のようなデータ構造を指します。

$$ \{w_1: [D_1,D_2...],w_2: [D_2,D_5...],... \} $$

ここでは、文書郡内に登場する単語$w$を**ターム**、タームに紐づいた文書情報の配列($[D_i,...]$)を**ポスティングリスト**と呼びます。

それでは例として、以下の3つの文書(映画タイトル)が検索対象となるような検索エンジンを想定して、転置インデックスを作成してみましょう。

1. **"Toy Story"**
2. **"The Wolf of Wall Street"**
3. **"The NeverEnding Story"**

ポスティングリストの各アイテムには、「文書id」と「各文書における単語の登場位置」を格納するとして、以下のような転置インデックスが得られます。

```JS
{
    "NeverEnding":[
        {"document_id": 3, "positions_in_document": [1]} // 文書id=3の文書("The NeverEnding Story")の1単語目(0から数える)に登場
    ],
    "Story":[
        {"document_id": 1, "positions_in_document": [1]},
        {"document_id": 3, "positions_in_document": [1]}, 
    ],
    "Street":[
        {"document_id": 2, "positions_in_document": [4]}
    ],
    "The":[
        {"document_id": 2, "positions_in_document": [0]}
        {"document_id": 3, "positions_in_document": [0]}
    ]
    ...
}

```

多くの検索エンジンでは、このように、**転置インデックスという非常にシンプルでわかりやすいデータ構造**を事前に作成・保存します。これによって、ユーザが要求する単語の含まれる文書群への高速なアクセスを実現しているのです。

以上が検索エンジンOmochi(および多くの検索エンジン)を支えるデータ構造・転置インデックスの説明になります。

# 3.転置インデックス型・全文検索エンジンOmochi

リポジトリの[README.md](https://github.com/YadaYuki/omochi/#readme)にも記載がありますが、今回実装した全文検索エンジンOmochiは以下のような特徴を持ちます。

- 転置インデックスを用いた全文検索エンジン.
- RESTful API 経由で、事前に登録した文書群を対象に検索が可能
- 複数単語を用いた検索は、AND検索・OR検索に対応
- 登録可能な言語：日本語, 英語

ここで、全文検索エンジンOmochiの内部構造を概観するために、概要図を見てみましょう.

![Omochiの概観図](https://user-images.githubusercontent.com/57289763/179801992-6963b38e-4d3b-44d1-9612-e91c374d194c.png)

概要図からわかる通り、検索エンジンOmochiは

- 文書の登録(転置インデックスの作成等も含む)を行う**Indexer**
- 情報要求に対する文書の検索処理を行う**Searcher**

という大きく分けて2つのパーツから構成されていることがわかります。

次章以降では、Omochiの全体的な設計に加え、それぞれのパーツに対する実装の詳細を見ていきましょう.

# 4 Omochiの技術選定

タイトルにもある通り、検索エンジンOmochiは言語としては[**Go**](https://go.dev/)を用いています。個人開発なので、使ってみたかったという背景も大きいですが、検索エンジンのように、形態素解析や関連性のスコアリングなど、**実行するロジックが複雑でありながら速度が求められるアプリケーション**と「Goの持つ高速性」はなかなか相性が良いのではないのでしょうか。

また、後の章でも触れますが、**デモで用いるテストデータ(数千 ~ 数万件程度の文書データ)を検索エンジンに登録する処理([seed.go](https://github.com/YadaYuki/omochi/blob/master/cmd/seeds/ja/seed.go))では、ゴルーチンによる並行処理を用いています**。そのため、Goの「新たなスレッド(ゴルーチン)の作成と作成した複数のゴルーチンの管理をシンプルに記述することができる点」も非常に魅力的であると感じました。

そして、周辺ツールとしては以下を用いています。

- [ent](https://entgo.io/)(ORM)
- [net/http](https://pkg.go.dev/net/http) + [chi](https://github.com/go-chi/chi) (Web application server)
- [Docker](https://www.docker.com/)
- [Mariadb](https://mariadb.com/kb/ja/mariadb/)(MySQL)

なお、今回OmochiではORMとして、Facebook製のentを採用しました。entには

- goのコードによるスキーマ(テーブル)の定義が可能
- 自動生成される静的型付けされた関数によって、SQL等を一切書かず、DBに対する操作ができる

等のメリットがあり、DBに対する操作を以下のようなコードで記述することが可能で、とても便利です。([公式Document](https://entgo.io/docs/getting-started#create-your-first-entity)より)
```go
func CreateUser(ctx context.Context, client *ent.Client) (*ent.User, error) {
    u, err := client.User.
        Create().
        SetAge(30).
        SetName("a8m").
        Save(ctx)
    ... 
```

以上がOmochiを構成する技術スタックの紹介になります

## 5.フォルダ構成概観(アプリケーション設計)

ここでは、Omochiのアプリケーション設計に関する説明を行います。アプリケーションの全体像を把握するために、フォルダ構成を概観してみましょう

```
├── LICENSE
├── README.md
├── cmd 
│   ├── api/ # サーバ起動のためのコード
│   │   └── main.go
│   ├── migrate/
│   └── seeds/
├── docker
│   ├── api/
│   └── db/
├── docker-compose.yml
├── docs
├── go.mod
├── go.sum
├── pkg # レイヤードアーキテクチャによるアプリケーションの実装
│   ├── common/ # 全体共通の処理・定数等の定義
│   │   ├── constant
│   │   └── slices
│   ├── config/ 
│   ├── domain
│   │   ├── entities
│   │   │   ├── document.go
│   │   │   ├── invert_index.go
│   │   │   ├── posting.go
│   │   │   ├── query.go
│   │   │   └── term.go
│   │   ├── repository
│   │   │   ├── document_repository.go
│   │   │   └── term_repository.go
│   │   └── service
│   │       ├── document_ranker.go
│   │       ├── indexer.go
│   │       ├── invert_index_compresser.go
│   │       ├── searcher.go
│   │       └── tokenizer.go
│   ├── ent/ # go(ent)によるDBのスキーマの定義・entにより自動生成されるコード
│   ├── errors/ 
│   ├── infrastructure
│   │   ├── compresser
│   │   │   ├── zlib_invert_index_compresser.go
│   │   │   └── zlib_invert_index_compresser_test.go
│   │   ├── documentranker
│   │   │   └── tfidfranker
│   │   ├── indexer
│   │   │   ├── indexer.go
│   │   │   └── indexer_test.go
│   │   ├── persistence
│   │   ├── searcher
│   │   │   ├── searcher.go
│   │   │   └── searcher_test.go
│   │   ├── tokenizer
│   │   │   ├── eng
│   │   │   └── ja
│   │   ...
│   ├── interface/ 
│   └── usecase/ 
└── scripts
...
```

フォルダ構成からわかる通り、今回は以下の4つのレイヤを持つレイヤードアーキテクチャを採用しました。

- インターフェース層(pkg/interface)
- アプリケーション層 (pkg/usecase)
- ドメイン層(pkg/domain)
- インフラストラクチャ層(pkg/infrastructure)

観測した限り、GoによるOSSでレイヤードアーキテクチャを採用しているものは少ないように感じられます。そんな中、Omochiでレイヤードアーキテクチャを採用した理由としては、**各レイヤーの外側からレイヤー内部の実装が見えないように抽象化を施すことによって、検索エンジンを構成する具体的な技術を剥がしやすくしたかったこと**が挙げられます。

ここでいう検索エンジンを構成する具体的な技術とは、例えば以下が挙げられます。

- 形態素解析・分かち書きのツール・ライブラリ(kagome,prose,nltk)
- 転置インデックス・文書を永続化するためのツール(RDB,NoSQL)
- データ操作のためのライブラリ(ent,gorm)
- スコアリングアルゴリズム(TfIdf,BM25)

以上の背景から、アプリケーションの設計として、レイヤードアーキテクチャを採用し、実装を行いました。

# 5.インデクシング機能の実装

# 6.サーチ機能の実装

# 7.ドラえもんのコミックタイトルを検索する(デモ)

# 8.まとめ

# 9.参考文献
